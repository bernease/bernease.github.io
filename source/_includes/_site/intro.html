<section class="intro">
  <div class="container">
    <p>I'm Bernease Herman, a data scientist at the University of Washington eScience Institute.</p>

    <h2>On <strong class="primary-color" style="font-weight:600">interpretable ML</strong>, <strong class="primary-color" style="font-weight:600">human-aware evaluation</strong>, and <strong class="primary-color" style="font-weight:600">entrepreneurship</strong></h2>

    <p>I am passionate about the translation of highly technical information<span class="footnote">*</span> to easily understandable forms. It is ethically imperative that the world's increasingly complex systems are understood by all they affect, regardless of technical training. To that end, my current research area is interpretable machine learning, where we seek to algorithmically generate human-understandable explanations of black-box models.<!-- &mdash; <a href="interpretableml">more on interpretable ML</a>--></p>

    <p>Another place I'm involved is the entrepreneurship community. I enjoy pondering commercialization opportunities, fault-tolerant machine learning UX, and designing the "final stretch" innovations that make ML solutions viable in the real world.<!-- &mdash; <a href="http://escience.washington.edu">more on entreprepreneurship</a>--></p>

    <p>Through my work with the UW eScience Institute's Data Science for Social Good (DSSG) and Winter Incubator programs, I've worked on problems as broad as data collection strategies in autonomous marine vehicles to predicting inequity in Seattle urban data. &mdash; <a href="http://escience.washington.edu">eScience website</a></p>

    <p class="footnote">*&emsp;e.g. machine learning models, concepts/definitions, and source code</p>
  </div>
</section>
